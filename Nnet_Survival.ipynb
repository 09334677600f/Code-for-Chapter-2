{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8VO5yHGyqae+iqKLsDddF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/09334677600f/Code-for-Chapter-2/blob/main/Nnet_Survival.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchtuples as tt\n",
        "from pycox import models\n",
        "from pycox.models.utils import pad_col, make_subgrid\n",
        "from pycox.preprocessing import label_transforms\n",
        "from pycox.models.interpolation import InterpolateLogisticHazard"
      ],
      "metadata": {
        "id": "pHAH_a2G0XtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV1nQ2RYzaFx"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class LogisticHazard(models.base.SurvBase):\n",
        "    \"\"\"\n",
        "    A discrete-time survival model that minimize the likelihood for right-censored data by\n",
        "    parameterizing the hazard function. Also known as  \"Nnet-survival\" [3].\n",
        "\n",
        "    The Logistic-Hazard was first proposed by [2], but this implementation follows [1].\n",
        "\n",
        "    Arguments:\n",
        "        net {torch.nn.Module} -- A torch module.\n",
        "\n",
        "    Keyword Arguments:\n",
        "        optimizer {Optimizer} -- A torch optimizer or similar. Preferably use torchtuples.optim instead of\n",
        "            torch.optim, as this allows for reinitialization, etc. If 'None' set to torchtuples.optim.AdamW.\n",
        "            (default: {None})\n",
        "        device {str, int, torch.device} -- Device to compute on. (default: {None})\n",
        "            Preferably pass a torch.device object.\n",
        "            If 'None': use default gpu if available, else use cpu.\n",
        "            If 'int': used that gpu: torch.device('cuda:<device>').\n",
        "            If 'string': string is passed to torch.device('string').\n",
        "        duration_index {list, np.array} -- Array of durations that defines the discrete times.\n",
        "            This is used to set the index of the DataFrame in `predict_surv_df`.\n",
        "\n",
        "    References:\n",
        "    [1] Håvard Kvamme and Ørnulf Borgan. Continuous and Discrete-Time Survival Prediction\n",
        "        with Neural Networks. arXiv preprint arXiv:1910.06724, 2019.\n",
        "        https://arxiv.org/pdf/1910.06724.pdf\n",
        "\n",
        "    [2] Charles C. Brown. On the use of indicator variables for studying the time-dependence of parameters\n",
        "        in a response-time model. Biometrics, 31(4):863–872, 1975.\n",
        "        https://www.jstor.org/stable/2529811?seq=1#metadata_info_tab_contents\n",
        "\n",
        "    [3] Michael F. Gensheimer and Balasubramanian Narasimhan. A scalable discrete-time survival model for\n",
        "        neural networks. PeerJ, 7:e6257, 2019.\n",
        "        https://peerj.com/articles/6257/\n",
        "    \"\"\"\n",
        "    label_transform = label_transforms.LabTransDiscreteTime\n",
        "\n",
        "    def __init__(self, net, optimizer=None, device=None, duration_index=None, loss=None):\n",
        "        self.duration_index = duration_index\n",
        "        if loss is None:\n",
        "            loss = models.loss.NLLLogistiHazardLoss()\n",
        "        super().__init__(net, loss, optimizer, device)\n",
        "\n",
        "    @property\n",
        "    def duration_index(self):\n",
        "        \"\"\"\n",
        "        Array of durations that defines the discrete times. This is used to set the index\n",
        "        of the DataFrame in `predict_surv_df`.\n",
        "\n",
        "        Returns:\n",
        "            np.array -- Duration index.\n",
        "        \"\"\"\n",
        "        return self._duration_index\n",
        "\n",
        "    @duration_index.setter\n",
        "    def duration_index(self, val):\n",
        "        self._duration_index = val\n",
        "\n",
        "    def predict_surv_df(self, input, batch_size=8224, eval_=True, num_workers=0):\n",
        "        surv = self.predict_surv(input, batch_size, True, eval_, True, num_workers)\n",
        "        return pd.DataFrame(surv.transpose(), self.duration_index)\n",
        "\n",
        "    def predict_surv(self, input, batch_size=8224, numpy=None, eval_=True, to_cpu=False,\n",
        "                     num_workers=0, epsilon=1e-7):\n",
        "        hazard = self.predict_hazard(input, batch_size, False, eval_, to_cpu, num_workers)\n",
        "        surv = (1 - hazard).add(epsilon).log().cumsum(1).exp()\n",
        "        return tt.utils.array_or_tensor(surv, numpy, input)\n",
        "\n",
        "\n",
        "    def predict_hazard(self, input, batch_size=8224, numpy=None, eval_=True, to_cpu=False,\n",
        "                       num_workers=0):\n",
        "        hazard = self.predict(input, batch_size, False, eval_, False, to_cpu, num_workers).sigmoid()\n",
        "        return tt.utils.array_or_tensor(hazard, numpy, input)\n",
        "\n",
        "    def interpolate(self, sub=10, scheme='const_pdf', duration_index=None):\n",
        "        \"\"\"Use interpolation for predictions.\n",
        "        There are two schemes:\n",
        "            `const_hazard` and `exp_surv` which assumes pice-wise constant hazard in each interval (exponential survival).\n",
        "            `const_pdf` and `lin_surv` which assumes pice-wise constant PMF in each interval (linear survival).\n",
        "\n",
        "        Keyword Arguments:\n",
        "            sub {int} -- Number of \"sub\" units in interpolation grid. If `sub` is 10 we have a grid with\n",
        "                10 times the number of grid points than the original `duration_index` (default: {10}).\n",
        "            scheme {str} -- Type of interpolation {'const_hazard', 'const_pdf'}.\n",
        "                See `InterpolateDiscrete` (default: {'const_pdf'})\n",
        "            duration_index {np.array} -- Cuts used for discretization. Does not affect interpolation,\n",
        "                only for setting index in `predict_surv_df` (default: {None})\n",
        "\n",
        "        Returns:\n",
        "            [InterpolateLogisticHazard] -- Object for prediction with interpolation.\n",
        "        \"\"\"\n",
        "        if duration_index is None:\n",
        "            duration_index = self.duration_index\n",
        "        return InterpolateLogisticHazard(self, scheme, duration_index, sub)"
      ]
    }
  ]
}